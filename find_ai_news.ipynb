{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find AI NEWS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_SEARCH_QUERIES = [\n",
    "    [\"New AI model\", \"AI model release\", \"AI model launch\", \"AI model update\", \"AI model upgrade\", \"AI model release date\"],\n",
    "    [\"AI open source\", \"HuggingFace\", \"AI Github\", \"AI Llama\"],\n",
    "    [\"AI breakthrough\", \"AI innovation\"],\n",
    "    [\"AI Tool\", \"AI feature\", \"AI software\", \"AI product\", \"AI service\", \"AI platform\", \"AI API\", \"AI application\", \"AI project\"],\n",
    "    [\"AI Assistant\", \"AI Personal Assistant\"],\n",
    "    [\"AI report\", \"AI book\", \"AI journal\", \"AI conference\", \"AI event\", \"AI competition\", \"AI challenge\", \"AI hackathon\", \"AI workshop\"],\n",
    "    [\"AI interview\", \"AI debate\", \"AI forum\"],\n",
    "    [\"AI business\", \"AI profession\", \"AI career\", \"AI job\", \"AI work\", \"AI employment\", \"AI salary\", \"AI income\", \"AI wage\", \"AI money\"],\n",
    "    [\"Generative AI\"],\n",
    "    [\"OpenAI\", \"GPT\"],\n",
    "    [\"Anthropic AI\", \"Claude AI\"],\n",
    "    [\"Gemini AI\", \"Google AI\", \"Deepmind\"],\n",
    "    [\"Mistral AI\"],\n",
    "    [\"Cohere AI\"],\n",
    "    [\"Meta AI\"],\n",
    "    [\"Perplexity AI\"],\n",
    "    [\"Microsoft AI\", \"Microsoft Copilot\"],\n",
    "    [\"AI Powered device\"],\n",
    "    [\"AI Robotics\", \"AI humanoid\", \"AI robot\", \"AI robots\"],\n",
    "    [\"AI research\", \"AI research paper\", \"AI research lab\", \"AI researcher\"],\n",
    "    [\"AI Agents\", \"AI Agent\", \"Autonomous AI\", \"AI Collaboration\"],\n",
    "    [\"LLM\", \"Large Language Model\", \"LLM Tokens\", \"LLM Context window\"],\n",
    "    [\"LLM Prompt\", \"LLM Prompting\", \"Prompt Engineering\", \"Prompt Tuning\", \"Prompt Evaluation\", \"Zero-shot LLM\", \"Few-shot LLM\"],\n",
    "    [\"LLM Training\", \"LLM Training data\", \"LLM Training cost\"],\n",
    "    [\"AI Dataset\", \"AI Datasets\"],\n",
    "    [\"AI Transformer\", \"AI Mamba\"],\n",
    "    [\"LLM Mobile\", \"LLM Phone\", \"Embedded LLM\", \"LLM on device\"],\n",
    "    [\"Small Language Model\", \"Small LLM\", \"AI SLM\"],\n",
    "    [\"AI Langchain\", \"AI Framework\", \"AI Library\", \"CrewAI\", \"LlamaIndex\"],\n",
    "    [\"AI Chatbot\"],\n",
    "    [\"low code AI\", \"no code AI\"],\n",
    "    [\"AI blockchain\"],\n",
    "    [\"AI Regulations\"],\n",
    "    [\"AI Intel\", \"AI groq\", \"AI AMD\", \"AI ARM\", \"AI Tesla Chips\", \"AI Tesla Dojo\"],\n",
    "    [\"AI Hardware\", \"AI Chip demand\", \"AI chip competition\"],\n",
    "    [\"AI Nvidia\"],\n",
    "    [\"AI Apple\"],\n",
    "    [\"AI Tesla\", \"AI Elon Musk\"],\n",
    "    [\"Twitter AI\", \"AI Grok\", \"xAI\"],\n",
    "    [\"AI Car\", \"AI self driving car\", \"AI autonomous car\", \"AI Waymo\", \"AI Cruise\", \"AI Uber\", \"AI Lyft\"],\n",
    "    [\"AI drone\"],\n",
    "    [\"AI Military\"],\n",
    "    [\"AI Competition\"],\n",
    "    [\"AI Startup\", \"AI Startups\"],\n",
    "    [\"AI funding\", \"AI investment\", \"AI venture capital\", \"AI acquisition\"],\n",
    "    [\"AI Avatar\", \"AI content generation\", \"AI content creation\", \"AI social media\", \"AI influencer\"],\n",
    "    [\"AI Adobe\"],\n",
    "    [\"AI tiktok\", \"AI Instagram\", \"AI Facebook\", \"AI Twitter\", \"AI Snapchat\", \"AI Youtube\", \"AI Reddit\", \"AI Pinterest\", \"AI Linkedin\"],\n",
    "    [\"AI Problem solving\", \"AI Reasoning\", \"AI planning\"],\n",
    "    [\"AI Cloud\", \"AI Cloud computing\", \"AI Cloud service\", \"AI Cloud platform\"],\n",
    "    [\"AI AWS\", \"AI Azure\", \"AI Google Cloud\"],\n",
    "    [\"AI Virtual Reality\", \"AI VR\", \"AI AR\", \"AI Augmented Reality\"],\n",
    "    [\"AI Video game\", \"AI Gaming\", \"AI Game\"],\n",
    "    [\"AI Education\", \"AI Learning\", \"AI School\", \"AI University\"],\n",
    "    [\"Explainable AI\", \"AI interpretability\", \"AI explainability\"],\n",
    "    [\"AI Image recognition\", \"Multimodal LLM\"],\n",
    "    [\"AI Image generation\", \"Midjourney\", \"OpenAI Dalle\", \"OpenAI Dall-e\", \"Stable diffusion\"],\n",
    "    [\"AI Video generation\", \"AI Video\", \"OpenAI Sora\", \"AI Video Analysis\", \"Google AI Lumiere\"],\n",
    "    [\"AI Music generation\", \"AI Music\"],\n",
    "    [\"AI Voice generation\", \"AI Voice synthesis\", \"AI voice recognition\"],\n",
    "    [\"AI Scandal\", \"AI Controversy\", \"AI trial\", \"AI lawsuit\"],\n",
    "    [\"AI Hack\", \"AI Cybersecurity\", \"AI Attack\", \"AI Jailbreak\"],\n",
    "    [\"AI Deepfake\", \"AI Deepfakes\", \"AI Deepfake detection\", \"AI Deepfake creation\"],\n",
    "    [\"AI detector\", \"AI detection\", \"AI detection tool\", \"AI detection software\"],\n",
    "    [\"AI Coding\", \"AI Programming\", \"Github Copilot\", \"AI Github\", \"AI Autonomous coding\"],\n",
    "    [\"AI AGI\", \"AI ASI\", \"AI Singularity\", \"AI Superintelligence\", \"AI SSI\"],\n",
    "    [\"AI Consciousness\", \"AI Sentience\", \"AI Emotion\", \"AI Creativity\", \"AI Art\"],\n",
    "    [\"AI Turing test\", \"AI Benchmark\", \"AI Evaluation\"],\n",
    "    [\"AI Brain\", \"AI Brain chip\"],\n",
    "    [\"Sam Altman\", \"Elon Musk AI\", \"Yann LeCun\", \"Ilya Sutskever\", \"Stuart Russell\", \"Demis Hassabis\", \"Jensen Huang\"],\n",
    "    [\"AI Economics\", \"AI Strategy\", \"AI Geopolitics\"],\n",
    "    [\"AI Power Usage\", \"AI Energy consumption\"],\n",
    "    [\"AI healthcare\"]\n",
    "]\n",
    "\n",
    "# TODO : localised searches \"AI China | IA France | AI Germany | AI UK | AI US | AI Russia | AI India | AI Japan | AI Korea | AI Canada | AI Australia\","
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q duckduckgo-search[lxml] tqdm pytz\n",
    "\n",
    "from duckduckgo_search import DDGS\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching: 100%|██████████| 244/244 [02:30<00:00,  1.62it/s, query=AI healthcare]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2160 unique results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "SLEEP_TIME = 0.2\n",
    "MAX_RESULTS = 30\n",
    "TIME_LIMIT = \"d\"\n",
    "\n",
    "duplicates = []\n",
    "\n",
    "def perform_search(queries:list[str]):\n",
    "    results = {}\n",
    "    ddgs = DDGS()\n",
    "\n",
    "    with tqdm(total=len(queries), desc=\"Searching\") as pbar:\n",
    "        for query in queries:\n",
    "            pbar.set_postfix(query=query)\n",
    "            search_results = ddgs.news(query, max_results=MAX_RESULTS, timelimit=TIME_LIMIT)\n",
    "            for result in search_results:\n",
    "                if result['url'] not in results:\n",
    "                    result['found_at'] = datetime.now(pytz.utc).isoformat()\n",
    "                    results[result['url']] = result\n",
    "                else:\n",
    "                    duplicates.append(result)\n",
    "            time.sleep(SLEEP_TIME)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "results = perform_search([query for queries in AI_SEARCH_QUERIES for query in queries])\n",
    "\n",
    "print(f\"Found {len(results)} unique results and {len(duplicates)} duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the dates to datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results.values():\n",
    "    if isinstance(result['date'], str):\n",
    "        result['date'] = datetime.fromisoformat(result['date'])\n",
    "    if isinstance(result['found_at'], str):\n",
    "        result['found_at'] = datetime.fromisoformat(result['found_at'])\n",
    "\n",
    "assert all(isinstance(result['date'], datetime) for result in results.values())\n",
    "assert all(isinstance(result['found_at'], datetime) for result in results.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = MongoClient(os.getenv(\"MONGODB_URI\"))\n",
    "\n",
    "db = client[\"blogdb\"]\n",
    "\n",
    "collection = db[\"ai_news\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 2108 documents\n",
      "Encountered 52 errors\n"
     ]
    }
   ],
   "source": [
    "from pymongo.errors import BulkWriteError\n",
    "\n",
    "assert all(isinstance(result['date'], datetime) for result in results.values())\n",
    "assert all(isinstance(result['found_at'], datetime) for result in results.values())\n",
    "\n",
    "\n",
    "try:\n",
    "    result = collection.insert_many(results.values(), ordered=False)\n",
    "    print(f\"Inserted {len(result.inserted_ids)} documents\")\n",
    "except BulkWriteError as e:\n",
    "    print(f\"Inserted {e.details['nInserted']} documents\")\n",
    "    print(f\"Encountered {len(e.details['writeErrors'])} errors\") # number of duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = f\"ai_news_{date.today().isoformat()}.csv\"\n",
    "\n",
    "df = pd.DataFrame(results.values())\n",
    "\n",
    "df.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dumps\n",
    "\n",
    "\n",
    "file_name = f\"ai_news_{date.today().isoformat()}.json\"\n",
    "\n",
    "with open(file_name, \"w\") as f:\n",
    "    f.write(dumps(results, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog-db-crR3mef3-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
